% ****** Start of file aipsamp.tex ******
%
%   This file is part of the AIP files in the AIP distribution for REVTeX 4.
%   Version 4.1 of REVTeX, October 2009
%
%   Copyright (c) 2009 American Institute of Physics.
%
%   See the AIP README file for restrictions and more information.
%
% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.1
%
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex  aipsamp
%  2)  bibtex aipsamp
%  3)  latex  aipsamp
%  4)  latex  aipsamp
%
% Use this file as a source of example code for your aip document.
% Use the file aiptemplate.tex as a template for your document.
\documentclass[%
 aip,
 jmp,%
 amsmath,amssymb,
%preprint,%
 reprint,%
%author-year,%
%author-numerical,%
]{revtex4-1}
\usepackage{textcomp}
\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines

\usepackage{enumerate}
\usepackage{color}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\usepackage{tikz}
\usetikzlibrary{automata,arrows,positioning}
\usepackage[parfill]{parskip} % new paragraph no ident
\usepackage{hyperref}

\begin{document}

\preprint{AIP/123-QED}

\title[Two Top-down Parsers, a Computer Construction assignment report]{Compiler: Two Top-down Parsers\\
A Go Implementation}% Force line breaks with \\
%\thanks{Footnote to title of article.}

\author{Ersi Ni}\thanks{15204230}
 \email{ersi.ni@ucdconnect.ie}
 \affiliation{University College Dublin, School of Computer Science}


\date{\today}% It is always \today, today,
             %  but any date may be explicitly specified

\begin{abstract}
This report explores the implementation of Top-down Parsers both in concept and in Go code.

\end{abstract}

\keywords{top-down parser, compiler construction, golang}
\maketitle



\section{Concept and Preparation}
In preparation a targeted grammar was modified such that there is no left-recursion in its production rules. This enables the top-down parser to be able to finish parsing. Further, the left-recursion eliminated (here after \textbf{LRE}) grammar was represented in program code, allowing parsers to access it directly.
\subsection{Targeted Grammar}
\begin{tabular}{lclr}
BExp 	&::=& BTerm	&	$|$\\
&&    BExp and BTerm	&$|$\\&&	    BExp or BTerm&\\
BTerm 	&::=& BFactor	&	$|$\\
&&	    not BTerm&\\BFactor&	::=& ( BExp )	&	$|$\\
&&	    id		&	$|$\\
&&	    BConst	&	$|$\\
&&	    id = num	&	$|$\\
&&	    id $>$ num	&	$|$\\
&&	    id $<$ num&\\BConst&	::=& true&		$|$\\&&	    false&
\end{tabular}


\textbf{Note that the original (appeared in assignment) grammar didn't included }\texttt{num <=> num}\textbf{ rules, this however conflicts with moodle statement that input1 are all valid sentences (input2 has mixed sentences). After careful consideration I have decided not to deviate from the assignment specification, this means that last 2 cases of input1 are bound to fail. }\label{note:rant}
\subsection{Preparation}
\subsubsection{Eliminating left recursion}
\begin{tabular}{lclr}
S	&$\rightarrow$& BExp \$\$\$			&\\
BExp	&$\rightarrow$& BTerm BExp2		&\\
BExp2	&$\rightarrow$& and BTerm BExp2	&$|$\\
		&&		or BTerm	 BExp2			&$|$\\
		&&		$\epsilon$				&\\
BTerm	&$\rightarrow$&	BFactor			&$|$\\
		&&		not BTerm				&\\
BFactor	&$\rightarrow$& ( BExp )			&$|$\\
		&&	   	id						&$|$\\
		&&	   	BConst					&$|$\\
		&&	   	id = num					&$|$\\
		&&	   	id $>$ num				&$|$\\
		&&	   	id $<$ num				&\\
BConst	&$\rightarrow$& true				&$|$\\
		&&	   	false					&
\end{tabular}

The original grammar had 13 productions, the \texttt{LRE} grammar has 15 productions.
\subsubsection{Grammar productions representation}

I chose to use (hash)map to represent the mapping from \texttt{LHS} (single symbol in our simple grammar) to \texttt{RHS}, a sequence of symbols containing terminals or non-terminals. 

The production mapping contains $\epsilon$ in the \texttt{RHS}, but it is not terminal and it was handled during parsing in separate fashion similar to boundary check.


\section{Backtracking Recursive-Descent Parser}
Parsing a sequence of symbol against given grammar is not an easy task, luckily the $LL$ grammar laid out a strategy that can be followed similar to searching a solution in graph. In fact, recursive-descent parsing is non-other than depth first search on a tree starting from \texttt{S} to every leaf matching a terminal at the corresponding position. The intricacies of this particular \texttt{DFS} is to maintain of invariants and examine all the conditions carefully.

As mentioned in \ref{note:rant}, when running RDP against \texttt{input1} it shows first 4 grammatical and last 2 ungrammatical. 6 and 4 for \texttt{input2}, respectively. Detailed output is attached as appendix.
\section{Predictive Parser}

\subsection{Left-factoring to produce $LL(1)$}

$LL(1)$ grammar is to eliminate ambiguity in \texttt{RHS} leading symbols, such that a parser with lookahead (1 in $LL(1)$ case) parsing $LL(1)$ wouldn't need to backtrack. 

\subsubsection{$LL(1)$ Grammar}
\begin{tabular}{lclr}
S	&$\rightarrow$& BExp \$\$\$			&\\
BExp	&$\rightarrow$& BTerm BExp2		&\\
BExp2	&$\rightarrow$& and BTerm BExp2	&$|$\\
		&&		or BTerm	 BExp2			&$|$\\
		&&		$\epsilon$				&\\
BTerm	&$\rightarrow$&	BFactor			&$|$\\
		&&		not BTerm				&\\
BFactor	&$\rightarrow$& ( BExp )			&$|$\\
		&&	   	id BFactorP				&$|$\\
		&&	   	BConst					&\\
BFactorP&$\rightarrow$&	$\epsilon$			&$|$\\
		&&		= num				&$|$\\
		&&	   	$>$ num				&$|$\\
		&&	   	$<$ num				&\\
BConst	&$\rightarrow$& true				&$|$\\
		&&	   	false					&
\end{tabular}
\subsubsection{Re-running backtracking RDP on $LL(1)$}

When re-running the backtracking RDP on $LL(1)$, it reveals that I made a mistake in applying Left-factoring: in order to let the resulting $LL(1)$ grammar "look" better I re-ordered the $\epsilon$ rule of the non-terminal \texttt{BFactorP} so that it sits below the term \texttt{< num}. This obviously creates different syntax and some of the results did not agree with each other across the two grammars. 

Parsing $LL(1)$ grammar would obviously generate different number count for tried productions, discarded mis-matches etc. because the "depth" is different in few production rules. But the final result indicating the validity of the sentence should be the same.

\subsection{FirstSet and FollowSet}
To build the non-backtracking predictive parser, knowledge from FirstSet and FollowSet is required.

A reenforced learning outcome of this assignment for me is the realisation that these sets are supposed to contains terminals (including artificial \texttt{End} token) only, with exception of $\epsilon$ in firstsets.

Attached output contains a separate section of computed first sets of sequences, followsets of non-terminals and a crude drawing of predictive table. I regret not having enough time to polish the drawing, I was in process of writing a 2D rendering routine to generate vector graph for the matrix, but it would be again too much unnecessary work.
\subsection{Predictive Parser}
In the previous sections routines were implemented for generating FirstSet for production RHS and FollowSets of Non-Terminals. These result were utilised in predictive table building, such that when parsing input tokens against this table the parser would not need to backtrack (or recurse, if a explicit stack were used). The majority of debugging effort were used in phase of Predictive Parser. The conditions and invariants is little more difficult to be kept in head compared to recursive-descent parser, especially the handling of $\epsilon$ added to the internal stack, the step most not be broken that input token index gets forwarded without it's counterpart, the top of the stack symbol, being properly processed. 
\section{Results}
A unified running result is attached to this report. It contains testing results, including the counting of matching tries for both parsers and their parsing conclusions. Also there is a detailed parsing test containing verbosely generated report of internal concrete states when parsing a string of textual content "\texttt{tom = 33 \$\$\$}". 

Recap on the counting result, it reveals that generally \texttt{dfs} on $LL(1)$ grammar used fewer attempts on finding correct generation path, and \texttt{predictiveParsing} without backtracking uses even fewer attempt. They agree with the theoretic expectation of the mentioned approaches. However it's note that this observation is not absolute, for example translated $LL(1)$ grammar contains greater or equal count of productions, therefore a particular generation path would appear to be slower than \texttt{LRE}. Similarly a particular path when matching predictive matrix against input symbol would take a longer path in some example.
\section{Appendix Overview}
This assignment is about 1000 lines of source code comment free. 9 pages of test results. 


\begin{enumerate}[$\surd$]
	\item source code listing: Parser 
	\begin{enumerate}[$\blacktriangleright$]
	\item parse.go; parse\_test.go
	\end{enumerate}
	\item test result / output
	\begin{enumerate}[$\blacktriangleright$]
	\item parser.output.pdf
	\end{enumerate}
\end{enumerate}

\rule{\textwidth}{2pt}

\end{document}
%
% ****** End of file aipsamp.tex ******
